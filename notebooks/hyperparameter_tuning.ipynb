{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nbimporter\n",
    "from format_data import FormatMLData\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "ml_data = FormatMLData(\"../data/ml_data_subset.tsv\").return_ml_data()",
   "id": "1f4610960172a27"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Hyperparameter Tuning for Logistic Regression Model",
   "id": "66f0fa29ccb421e4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Hyperparameter tuning on subset\n",
    "# Note the final_selected_features_logistic_regression differ to those on the full dataset - these features are selected from the subset data\n",
    "final_selected_features_logistic_regression = ['EXOMISER_GENE_PHENO_SCORE', 'EXOMISER_GENE_VARIANT_SCORE', 'WEIGHTED_PS1', 'WEIGHTED_PS2', 'WEIGHTED_PP5', 'WEIGHTED_PM5', 'WEIGHTED_PM4', 'WEIGHTED_PM2']\n",
    "\n",
    "X = ml_data.training_data.select(final_selected_features_logistic_regression)\n",
    "y = ml_data.training_data.select([\"CAUSATIVE_VARIANT_STATUS\"]).to_series().to_numpy().ravel()\n",
    "\n",
    "# Define parameter grids\n",
    "param_grid_l1_l2 = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['liblinear', 'saga'],\n",
    "    'max_iter': [100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "param_grid_elasticnet = {\n",
    "    'penalty': ['elasticnet'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "    'solver': ['saga'],\n",
    "    'l1_ratio': [0.1, 0.5, 0.9],\n",
    "    'max_iter': [100, 200, 500, 1000]\n",
    "}\n",
    "\n",
    "combined_param_grid = [param_grid_l1_l2, param_grid_elasticnet]\n",
    "\n",
    "lr = LogisticRegression(random_state=42)\n",
    "\n",
    "# Perform Grid Search\n",
    "lr_grid_search = GridSearchCV(\n",
    "    estimator=lr,\n",
    "    param_grid=combined_param_grid,\n",
    "    cv=10,\n",
    "    scoring='roc_auc',  \n",
    "    n_jobs=-1,\n",
    "    error_score='raise',\n",
    "    return_train_score= True,    \n",
    ")\n",
    "lr_grid_search.fit(X, y)\n",
    "\n",
    "print(\"Best parameters for Logistic Regression:\", lr_grid_search.best_params_)\n",
    "print(\"Best cross-validated accuracy:\", lr_grid_search.best_score_)\n",
    "\n",
    "# Store train and test scores - look for signs of overfitting\n",
    "results_df = pd.DataFrame(lr_grid_search.cv_results_)\n",
    "results_df.to_csv(\"logistic_regression_grid_search.tsv\", sep='\\t')"
   ],
   "id": "61f66bba6b494ad0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
